{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_-itVgrAhGV"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaN1g3ZGAj6T"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stP9BWw42Y62",
    "outputId": "b5bcbf17-68b8-489f-9c46-14e99fb9eb56"
   },
   "outputs": [],
   "source": [
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgIVb1Zc2u1H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, EnsureTyped,\n",
    "    Orientationd, Spacingd, NormalizeIntensityd, ScaleIntensityRanged,\n",
    "    CropForegroundd, RandCropByPosNegLabeld,\n",
    "    RandFlipd, RandRotated, RandZoomd, RandGaussianNoised,\n",
    "    AsDiscreted, SpatialPadd\n",
    ")\n",
    "from monai.data import CacheDataset, DataLoader, load_decathlon_datalist\n",
    "from monai.utils import set_determinism\n",
    "from monai.apps import DecathlonDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakDt8LTAoC_"
   },
   "source": [
    "### Get DecathlonDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KN0cR3Z3A0J"
   },
   "source": [
    "**class monai.apps.DecathlonDataset**\n",
    "\n",
    "- task – which task to download and execute: one of list (“Task01_BrainTumour”, “Task02_Heart”, “Task03_Liver”, “Task04_Hippocampus”, “Task05_Prostate”, “Task06_Lung”, “Task07_Pancreas”, “Task08_HepaticVessel”, “Task09_Spleen”, “Task10_Colon”).\n",
    "\n",
    "- transform – transforms to execute operations on input data.\n",
    "\n",
    "- section – expected data section, can be: training, validation or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34-aUoTJrII6",
    "outputId": "866b3142-3870-40a5-d2f5-0668917f33f0"
   },
   "outputs": [],
   "source": [
    "train_data = DecathlonDataset(root_dir=\"/content/dataset\", task=\"Task05_Prostate\", transform=None, section=\"training\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3oDjasltrzQ"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbfZapdqpr0o"
   },
   "source": [
    "**Separate train/val transforms.** Add augmentation (flip/rotate/zoom/noise) only to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btgnJjDDpOWf"
   },
   "outputs": [],
   "source": [
    "set_determinism(42)  # Seeds for random generator\n",
    "\n",
    "# Common (both train/val)\n",
    "common = [\n",
    "    LoadImaged(keys=[\"image\",\"label\"]),  # Load both image data and metadata.\n",
    "    EnsureChannelFirstd(keys=[\"image\",\"label\"]),  # Adjust or add the channel dimension of input data to ensure channel_first shape.\n",
    "    Orientationd(keys=[\"image\",\"label\"], axcodes=\"LPS\"),  # LPS (left-posterior-superior) : (x-axis, y-axis, z-axis)\n",
    "    Spacingd(keys=[\"image\",\"label\"], pixdim=(1.0, 1.0, 3.0), mode=(\"bilinear\",\"nearest\")),  # Resample input image into the specified pixdim - 'bilinear' for image and 'nearest-neighbor' for label\n",
    "    NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),  # Normalize only non-zero values or entire image - Calculate mean and std on each channel separately.\n",
    "    CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\"),  # Crop an image using a bounding box to help training and evaluation if the valid part is small in the whole medical image.\n",
    "    EnsureTyped(keys=[\"image\",\"label\"]),  # Ensure the input data to be a PyTorch Tensor or numpy array\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbRdfngipypa"
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(common + [\n",
    "    SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(192, 192, 32)),\n",
    "    # Balanced patch sampling (Positive patch: foreground anatomy - Negative patch: background)\n",
    "    RandCropByPosNegLabeld(  # Crop random fixed sized regions with the center being a foreground or background voxel (3d pixel) based on the Pos Neg Ratio.\n",
    "        keys=[\"image\",\"label\"],\n",
    "        label_key=\"label\",\n",
    "        image_key=\"image\",\n",
    "        spatial_size=(96,96,32),\n",
    "        pos=1, neg=1,  #  Ratio: pos / (pos + neg) - for the probability to pick a foreground voxel as a center rather than a background voxel.\n",
    "        num_samples=1\n",
    "    ),\n",
    "    # 3D Augmentations\n",
    "    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=0),  # Randomly flips the image along x direction (left/right).\n",
    "    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=1),  # Randomly flips the image along y direction (front/back).\n",
    "    RandFlipd(keys=[\"image\",\"label\"], prob=0.5, spatial_axis=2),  # Randomly flips the image along z direction (up/down).\n",
    "    RandRotated(keys=[\"image\",\"label\"], prob=0.2, range_x=0.2, range_y=0.2, range_z=0.2, mode=(\"bilinear\",\"nearest\")),  # Bilinear: 2D image — interpolate between 4 neighboring pixels.\n",
    "    RandZoomd(keys=[\"image\",\"label\"], prob=0.2, min_zoom=0.9, max_zoom=1.1, mode=(\"trilinear\",\"nearest\")),  # Trilinear: 3D volume — interpolate between 8 neighboring voxels.\n",
    "    RandGaussianNoised(keys=[\"image\"], prob=0.15, mean=0.0, std=0.05),\n",
    "])\n",
    "\n",
    "val_transforms = Compose(common + [\n",
    "    AsDiscreted(keys=[\"label\"], to_onehot=3)  # Convert input value to One-Hot format (set to_one_hot=N, N is the number of classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XTW309MqQ78"
   },
   "outputs": [],
   "source": [
    "# Load image/label paths of decathlon challenge from JSON file\n",
    "data_root = \"/content/dataset\"\n",
    "datalist = load_decathlon_datalist(f\"{data_root}/Task05_Prostate/dataset.json\", data_list_key=\"training\")\n",
    "\n",
    "# Split Training & Validation Data\n",
    "val_fraction = 0.1\n",
    "split = int(len(datalist)*(1.0 - val_fraction))\n",
    "train_files, val_files = datalist[:split], datalist[split:]\n",
    "\n",
    "# Cache Data: It just returns the cached data instead of re-running the transforms — much faster.\n",
    "train_ds = CacheDataset(train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)  # cache everything\n",
    "val_ds   = CacheDataset(val_files,   transform=val_transforms,   cache_rate=1.0, num_workers=4)\n",
    "\n",
    "# Load Data\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtmH1ph_Aaka"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud26MV89CNbD",
    "outputId": "2d14c262-5eb4-4244-dcba-be472b20179e"
   },
   "outputs": [],
   "source": [
    "val_loader.dataset[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlsUFMrmrdii",
    "outputId": "93352c84-e6c2-4e27-9dea-e0db42db34c4"
   },
   "outputs": [],
   "source": [
    "train_loader.dataset[0][0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6aEyvqmtBxX",
    "outputId": "03defe8d-f42b-4d12-c803-c4e2f54e65a6"
   },
   "outputs": [],
   "source": [
    "train_loader.dataset[0][0]['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "ALA_koyCsyRj",
    "outputId": "ebe76ccf-6573-4316-c912-db0847dcef96"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_loader.dataset[0][0]['image'][0, :, :, 10])\n",
    "plt.subplot(122)\n",
    "plt.imshow(train_loader.dataset[0][0]['label'][0, :, :, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "226g59nT9WZb"
   },
   "outputs": [],
   "source": [
    "img = train_loader.dataset[0][0]['image'][0, :, :, 10].numpy()\n",
    "label = train_loader.dataset[0][0]['label'][0, :, :, 10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CClT-Eb3_9BG",
    "outputId": "8048b98a-03eb-43af-c62d-b2696982b6f9"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "UC5nHtgD9A2p",
    "outputId": "f571010a-03cc-4b8c-d4c4-b7db77aae0d5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.pcolormesh(img.T, cmap='Greys_r')\n",
    "plt.colorbar(label='HU')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.pcolormesh(label.T, cmap='Greys_r')\n",
    "plt.colorbar(label='HU')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdOXhk-qA0Yf"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt9NY2CfaO-m"
   },
   "source": [
    "MONAI 3D UNetR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfVPVDlHDxS8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data.utils import decollate_batch\n",
    "from monai.transforms import AsDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cowy8kKTaZRp"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# \"labels\": {\n",
    "#    \"0\": \"background\",\n",
    "#    \"1\": \"PZ\",\n",
    "#    \"2\": \"TZ\"\n",
    "#  }, -> 3 labels\n",
    "n_classes = 3\n",
    "\n",
    "model = SwinUNETR(\n",
    "    in_channels=2,\n",
    "    out_channels=3,\n",
    "    feature_size=48,  # must match pretrained\n",
    "    depths=(2, 2, 2, 2),  # matches pretrained config\n",
    "    num_heads=(3, 6, 12, 24),  # matches pretrained config\n",
    "    window_size=(7, 7, 7),  # local window size\n",
    "    mlp_ratio=4.0,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    norm_name=\"instance\",\n",
    "    spatial_dims=3,\n",
    "    use_checkpoint=True,  # saves memory\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEI_gmaTxv29",
    "outputId": "b3ca8dcb-4924-4ec6-cd7d-78479a2b7d43"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy1wwB8VwY80"
   },
   "source": [
    "Load Pre-Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fMQtyWzuFdU",
    "outputId": "b0a61cb6-0d4b-452c-ae85-6e55ca969692"
   },
   "outputs": [],
   "source": [
    "%cd model\n",
    "!wget https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/model_swinvit.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_qe87uFuYXv"
   },
   "outputs": [],
   "source": [
    "weight = torch.load(\"./model_swinvit.pt\", weights_only=True)\n",
    "model.load_from(weights=weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMEx9TVywT42"
   },
   "source": [
    "Loss, Optimizer, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djkDI7b4wVgI"
   },
   "outputs": [],
   "source": [
    "loss_fn = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=n_classes)\n",
    "post_label = AsDiscrete(to_onehot=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaFrg2Hbv2YS"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32DK2PqJ7F9z"
   },
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "\n",
    "# Delete your model, optimizer, and any GPU tensors\n",
    "del model, optimizer, train_loader, val_loader\n",
    "del images, labels, outputs, loss\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omPPdYBIY9LQ",
    "outputId": "b61f7867-91aa-477a-9d24-c1c64bbf31f1"
   },
   "outputs": [],
   "source": [
    "epoch_num = 20\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print(f\"Epoch {epoch+1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "      images, labels = (batch[\"image\"].to(device), batch[\"label\"].to(device))\n",
    "\n",
    "      with torch.autocast(\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      nn.utils.clip_grad_norm_(model.parameters(), 12.0)\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"  Train Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szwb3odyBOl_"
   },
   "outputs": [],
   "source": [
    "# Save the model's state_dict\n",
    "PATH = \"my_model.pth\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tn5Bf3f6BNpJ"
   },
   "source": [
    "# Test & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Z4IwO_HC2FA",
    "outputId": "e56b667d-1e5a-4ed4-b70d-2916ecb6f0ef"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    for batch in train_loader:\n",
    "        img, label = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "        pred = model(img)                  # [B, C, H, W, D]\n",
    "        pred_soft = torch.softmax(pred, dim=1)\n",
    "        pred_mask = torch.argmax(pred_soft, dim=1)  # [B, H, W, D]\n",
    "        break  # just first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "EQ5C3X-nFO4A",
    "outputId": "2324da36-c5b2-47f9-ec3b-7342f4e5ca0e"
   },
   "outputs": [],
   "source": [
    "img_np = img.cpu().numpy()[0, 0]        # shape: H x W x D\n",
    "label_np = label.cpu().numpy()[0, 0]\n",
    "pred_np = pred_mask.cpu().numpy()[0]\n",
    "\n",
    "slice_idx = img_np.shape[-1] // 2\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_np[:, :, slice_idx], cmap=\"gray\")\n",
    "plt.title(\"Image\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(label_np[:, :, slice_idx], cmap=\"gray\")\n",
    "plt.title(\"Ground Truth\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_np[:, :, slice_idx], cmap=\"gray\")\n",
    "plt.imshow(pred_np[:, :, slice_idx], cmap=\"jet\", alpha=0.5)\n",
    "plt.title(\"Prediction Overlay\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RVt1WeOOu0V"
   },
   "source": [
    "# Useful Links\n",
    "\n",
    "[swin_unetr_btcv_segmentation_3d](https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/swin_unetr_btcv_segmentation_3d.ipynb)\n",
    "\n",
    "[Prostate_MRI_Anatomy_Model](https://github.com/Project-MONAI/tutorials/blob/main/model_zoo/TCIA_PROSTATEx_Prostate_MRI_Anatomy_Model.ipynb)\n",
    "\n",
    "[MONAI Applications](https://docs.monai.io/en/stable/apps.html)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
